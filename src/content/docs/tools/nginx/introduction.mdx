---
title: Giới thiệu Nginx
description: Nginx
lastUpdated: 2025-08-01
editUrl: https://github.com/OssiLV/OLV-NoteBook/blob/main/src/content/docs/tools/nginx.mdx
---

## Thời kỳ đầu của Web: Mọi thứ đơn giản

Vào những ngày đầu của internet, cách hoạt động của web khá đơn giản:

-   Trình duyệt (browser) gửi yêu cầu đến **máy chủ web** (web server) để lấy một trang web.
-   Máy chủ web là một máy tính chạy phần mềm chuyên dụng, có nhiệm vụ:
-   Tạo trang web (bao gồm văn bản, hình ảnh, liên kết, v.v.).
-   Gửi trang web đó về trình duyệt để hiển thị cho người dùng.

Phần mềm web server phổ biến thời kỳ đầu là **Apache HTTP Server**. Sau này, **Nginx** (ra mắt năm 2004) trở nên phổ biến nhờ hiệu năng cao, khả năng xử lý đồng thời nhiều yêu cầu, và sử dụng tài nguyên hiệu quả.

## Khi Web trở nên phổ biến: Vấn đề về tải

Khi internet phát triển, các trang web lớn bắt đầu nhận được **hàng nghìn hoặc hàng triệu yêu cầu** cùng lúc. Một máy chủ duy nhất không đủ sức xử lý lượng lớn yêu cầu này do giới hạn phần cứng và phần mềm.

Giải pháp là gì? **Sử dụng nhiều máy chủ hơn!**

-   Ví dụ: Triển khai 10 máy chủ web chạy Nginx để chia sẻ tải.
-   Vấn đề: Làm sao để phân phối yêu cầu từ trình duyệt đến các máy chủ này một cách hiệu quả? Đây là lúc **cân bằng tải (load balancing)** trở nên cần thiết.

## Cân bằng tải (Load Balancing) là gì?

Nginx không chỉ là một web server mà còn có thể hoạt động như một **reverse proxy** để cân bằng tải. Reverse proxy khác với forward proxy ở chỗ:

-   **Forward proxy**: Đại diện cho client, chuyển tiếp yêu cầu đến internet (thường dùng để ẩn danh hoặc vượt qua giới hạn mạng).
-   **Reverse proxy**: Đại diện cho máy chủ, nhận yêu cầu từ client và phân phối đến các máy chủ web phía sau (backend).

Vai trò của Nginx như một reverse proxy:

-   **Nhận yêu cầu** từ trình duyệt, giống như một "người trung gian".
-   **Phân phối yêu cầu** đến một trong các máy chủ web backend dựa trên thuật toán được cấu hình, ví dụ:
-   **Round Robin**: Phân phối yêu cầu lần lượt đến từng máy chủ.
-   **Least Connections**: Gửi yêu cầu đến máy chủ có ít kết nối đang xử lý nhất.
-   **IP Hash**: Gửi yêu cầu từ cùng một địa chỉ IP đến cùng một máy chủ để đảm bảo tính nhất quán.

Nhờ vậy, Nginx vừa là web server, vừa là reverse proxy mạnh mẽ với khả năng cân bằng tải.

## Các tính năng nổi bật của Nginx như một Reverse Proxy

Ngoài cân bằng tải, Nginx còn cung cấp nhiều tính năng mạnh mẽ khác khi hoạt động như một **reverse proxy**:

### 1. Lưu trữ tạm (Caching)

Hãy tưởng tượng một bài báo trên _VNExpress_ được hàng triệu người đọc cùng lúc. Nếu mỗi yêu cầu đều yêu cầu máy chủ web phải:

-   Lấy dữ liệu từ cơ sở dữ liệu.
-   Tạo lại trang web với văn bản, hình ảnh, và liên kết.
-   Gửi phản hồi về trình duyệt.

Quá trình này rất **tốn tài nguyên** và làm chậm hệ thống.

Giải pháp là **caching**:

-   Nginx tạo một bản sao của trang web (hoặc tài nguyên tĩnh như hình ảnh, CSS) **một lần duy nhất**.
-   Lưu bản sao này trong bộ nhớ hoặc đĩa và gửi nó cho mọi yêu cầu sau, thay vì tạo lại từ đầu.
-   Kết quả: **Tăng tốc độ tải**, **tiết kiệm tài nguyên** máy chủ.

### 2. Tăng cường bảo mật

Khi bạn vận hành hệ thống lớn với hàng chục hoặc hàng trăm máy chủ (như hệ thống ngân hàng trực tuyến), việc để **tất cả máy chủ đều tiếp xúc trực tiếp với internet** là một rủi ro lớn:

-   Hacker có thể tấn công từng máy chủ để tìm lỗ hổng.
-   Các cuộc tấn công DDoS (tấn công từ chối dịch vụ) có thể dễ dàng nhắm vào nhiều máy chủ.

Giải pháp là sử dụng **Nginx như một reverse proxy** làm điểm truy cập duy nhất:

-   Chỉ Nginx được tiếp xúc với internet, còn các máy chủ web backend được ẩn đi, giảm **bề mặt tấn công** (attack surface).
-   Nginx hỗ trợ **mã hóa giao tiếp** với **SSL/TLS**:
-   Yêu cầu tất cả kết nối phải sử dụng HTTPS (cổng 443).
-   Từ chối các yêu cầu không mã hóa.
-   Có thể chuyển tiếp yêu cầu mã hóa đến backend hoặc xử lý giải mã tại proxy.
-   Nginx cũng có thể được cấu hình để chống lại các cuộc tấn công DDoS bằng cách giới hạn tần suất yêu cầu (rate limiting).

### 3. Nén dữ liệu (Compression)

Hãy nghĩ về một nền tảng như _YouTube_, nơi hàng triệu người xem video cùng lúc. Nếu Nginx gửi toàn bộ dữ liệu video chất lượng cao mà không tối ưu, nó sẽ:

-   Tốn rất nhiều **băng thông**.
-   Làm chậm tốc độ truyền tải.

Giải pháp là **nén dữ liệu**:

-   Nginx hỗ trợ nén các tệp lớn (như HTML, CSS, JavaScript, hoặc video) trước khi gửi đến trình duyệt, sử dụng các thuật toán như **Gzip** hoặc **Brotli**.
-   Lợi ích:
-   **Tiết kiệm băng thông** cho cả máy chủ và người dùng.
-   **Tăng tốc độ tải** nội dung.
-   Nginx còn hỗ trợ gửi dữ liệu theo **từng phần (chunked transfer encoding)**, giúp người dùng bắt đầu xem nội dung (như video) trong khi phần còn lại vẫn đang được truyền tải.

### 4. Hỗ trợ giao thức hiện đại

Nginx liên tục được cập nhật để hỗ trợ các giao thức mới:

-   **HTTP/3 (QUIC)**: Giao thức thế hệ mới, cải thiện tốc độ và độ tin cậy so với HTTP/2, đặc biệt trong môi trường mạng không ổn định.
-   **gRPC**: Hỗ trợ giao tiếp hiệu quả giữa các microservices trong hệ thống phân tán.
-   **WebSocket**: Cho phép giao tiếp hai chiều liên tục giữa client và server, phù hợp với ứng dụng thời gian thực như chat hoặc game online.

## Cấu hình Nginx như thế nào?

Để tận dụng các tính năng trên, bạn cần cấu hình Nginx thông qua **tệp cấu hình** (thường là `nginx.conf` hoặc các tệp trong thư mục `/etc/nginx/`). Tệp này sử dụng các **chỉ thị (directives)** để định nghĩa:

-   **Chế độ hoạt động**: Nginx có thể hoạt động như **web server** (phục vụ tệp tĩnh) hoặc **reverse proxy** (chuyển tiếp yêu cầu).
-   **Cổng lắng nghe**: Ví dụ, cổng 80 (HTTP) hoặc cổng 443 (HTTPS).
-   **Cấu hình SSL**: Chỉ định chứng chỉ SSL (public key, private key) để mã hóa giao tiếp.
-   **Cân bằng tải**: Xác định danh sách máy chủ backend và thuật toán (như Round Robin, Least Connections).
-   **Caching**: Quy định thời gian lưu trữ bản sao nội dung và vị trí lưu trữ (bộ nhớ hoặc đĩa).
-   **Nén dữ liệu**: Kích hoạt Gzip hoặc Brotli, chỉ định loại tệp cần nén.

**Ví dụ cấu hình đơn giản cho reverse proxy với cân bằng tải**:

```nginx
http {
    upstream backend_servers {
        least_conn; # Sử dụng thuật toán Least Connections
        server backend1.example.com;
        server backend2.example.com;
        server backend3.example.com;
    }

    server {
        listen 80;
        server_name example.com;

        location / {
            proxy_pass http://backend_servers;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }
    }
}
```

Cấu hình này:

-   Định nghĩa một nhóm máy chủ backend (`backend_servers`) với thuật toán `least_conn`.
-   Lắng nghe trên cổng 80 và chuyển tiếp yêu cầu đến các máy chủ backend.

Để bảo mật hơn, bạn có thể thêm cấu hình HTTPS:

```nginx
server {
listen 443 ssl;
server_name example.com;

    ssl_certificate /path/to/cert.pem;
    ssl_certificate_key /path/to/key.pem;

    location / {
        proxy_pass http://backend_servers;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
```

Cấu hình của Nginx rất linh hoạt, với hàng chục chỉ thị phổ biến (như `proxy_`, `http`, `server`, `location`) để tùy chỉnh theo nhu cầu.

## Nginx và Kubernetes

-   Trong các hệ thống hiện đại như Kubernetes, Nginx thường được sử dụng như một Ingress Controller:
-   Ingress Controller là một reverse proxy nâng cao, nhận lưu lượng từ ngoài cụm Kubernetes và chuyển tiếp đến các dịch vụ (services) bên trong dựa trên các quy tắc (rules) được định nghĩa trong Ingress resources.
-   Ví dụ: Chuyển yêu cầu đến example.com/api tới dịch vụ API và example.com/web tới dịch vụ web.
-   Nginx là một trong những Ingress Controller phổ biến nhất nhờ:
    -   **Hiệu năng cao**: Xử lý hàng nghìn yêu cầu mỗi giây với tài nguyên tối thiểu.
    -   **Tính linh hoạt**: Hỗ trợ cấu hình phức tạp, như viết lại URL (URL rewriting) hoặc kiểm soát truy cập.
    -   **Cộng đồng lớn**: Có nhiều tài liệu và plugin hỗ trợ.

Nginx còn được sử dụng trong các kiến trúc **microservices** và **serverless**, nơi nó đảm nhận vai trò như một API Gateway hoặc proxy trung gian.

## Tại sao cần cả Nginx Load Balancer và Cloud Load Balancer?

Bạn có thể thắc mắc: "Các nền tảng đám mây như AWS, Google Cloud, hay Azure đều cung cấp bộ cân bằng tải (load balancer) riêng, vậy tại sao vẫn cần Nginx trong Kubernetes?"

Câu trả lời là **Cloud Load Balancer** và **Nginx Ingress Controller** hoạt động ở **các tầng khác nhau** trong kiến trúc hệ thống, bổ trợ lẫn nhau để đảm bảo hiệu suất, bảo mật, và khả năng định tuyến thông minh.

### 1. Cloud Load Balancer

-   **Vai trò**: Là **điểm truy cập công khai** (public entry point) nhận yêu cầu từ trình duyệt hoặc client qua internet.
-   **Chức năng**:
    -   Chuyển tiếp yêu cầu đến cụm Kubernetes thông qua một **dịch vụ (Service)** loại **LoadBalancer** trong cụm.
    -   Hỗ trợ các tính năng như **SSL termination**, phân phối lưu lượng, và bảo vệ DDoS (tùy thuộc vào nhà cung cấp đám mây).
    -   Ví dụ: AWS Elastic Load Balancer (ELB), Google Cloud Load Balancer, hoặc Azure Load Balancer.

### Nginx Ingress Controller

-   **Vai trò**: Hoạt động **bên trong cụm Kubernetes**, nhận lưu lượng từ Cloud Load Balancer và phân phối đến các **dịch vụ (services)** phù hợp.
-   **Chức năng**:
    -   Định tuyến yêu cầu dựa trên **URL** hoặc các quy tắc phức tạp được định nghĩa trong **Ingress resources**.
    -   Hỗ trợ các tính năng như **URL rewriting**, **rate limiting**, và **WebSocket**.
-   **Ví dụ**:
    -   Yêu cầu đến `example.com/online-cart` được chuyển đến microservice giỏ hàng.
    -   Yêu cầu đến `example.com/payment` được chuyển đến dịch vụ thanh toán.

### Lợi ích của mô hình kết hợp

-   **Bảo mật cao hơn**: Các thành phần trong cụm Kubernetes (như Pods, Services) không tiếp xúc trực tiếp với internet. Cloud Load Balancer đóng vai trò như một tầng bảo vệ, giảm **bề mặt tấn công** (attack surface).
-   **Định tuyến thông minh**: Nginx Ingress Controller hỗ trợ các quy tắc định tuyến phức tạp, cho phép phân phối lưu lượng dựa trên đường dẫn URL, tên miền, hoặc các tiêu chí khác.
-   **Tối ưu hiệu suất**: Cloud Load Balancer xử lý lưu lượng thô từ internet, trong khi Nginx tối ưu hóa định tuyến bên trong cụm, tận dụng các tính năng như **caching** hoặc **nén dữ liệu**.
-   **Hỗ trợ giao thức hiện đại**: Nginx Ingress Controller hỗ trợ **HTTP/3 (QUIC)**, **gRPC**, và **WebSocket**, phù hợp với các ứng dụng thời gian thực hoặc microservices.

**Lưu ý**: Trong một số trường hợp (như cụm Kubernetes on-premises), bạn có thể không cần Cloud Load Balancer mà sử dụng các giải pháp như **MetalLB** hoặc **External IP** để tiếp nhận lưu lượng trực tiếp vào Ingress Controller.

## Nginx Ingress Controller trong Kubernetes

Trong môi trường Kubernetes, **Nginx Ingress Controller** là một **reverse proxy** nâng cao, được triển khai dưới dạng **Deployment** hoặc **DaemonSet** trong cụm. Vai trò của nó bao gồm:

-   **Nhận lưu lượng**: Từ Cloud Load Balancer hoặc External IP thông qua một dịch vụ Kubernetes loại **LoadBalancer** hoặc **NodePort**.
-   **Phân phối lưu lượng**: Đến các dịch vụ (services) phù hợp dựa trên cấu hình trong **Ingress resources**.
-   **Hỗ trợ định tuyến phức tạp**: Ví dụ, chuyển hướng dựa trên đường dẫn URL, tên miền, hoặc các tiêu chí tùy chỉnh.
-   **Tính năng nâng cao**:
-   **Caching**: Lưu trữ tạm nội dung tĩnh để giảm tải cho backend.
-   **Rate limiting**: Giới hạn tần suất yêu cầu để chống tấn công DDoS.
-   **SSL/TLS**: Hỗ trợ mã hóa giao tiếp và quản lý chứng chỉ SSL.

### Cấu hình Nginx Ingress Controller

Để triển khai Nginx Ingress Controller, bạn cần:

-   **Cài đặt Nginx Ingress Controller**: Sử dụng **Helm charts**, **YAML manifests**, hoặc các công cụ quản lý hạ tầng như **Pulumi** hoặc **Terraform**.
-   **Định nghĩa Ingress resources**: Tệp YAML xác định các quy tắc định tuyến, ví dụ:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
    name: example-ingress
    annotations:
        nginx.ingress.kubernetes.io/rewrite-target: /
spec:
    ingressClassName: nginx
    rules:
        - host: example.com
          http:
              paths:
                  - path: /online-cart
                    pathType: Prefix
                    backend:
                        service:
                            name: cart-service
                            port:
                                number: 80
                  - path: /payment
                    pathType: Prefix
                    backend:
                        service:
                            name: payment-service
                            port:
                                number: 80
```

## So sánh Nginx và Apache Web Server

Cả Nginx và Apache Web Server đều là các phần mềm mạnh mẽ, nhưng chúng có những điểm khác biệt phù hợp với các trường hợp sử dụng khác nhau.

### 1. Điểm tương đồng

-   Cả hai đều có thể hoạt động như **web server** (phục vụ tệp tĩnh) và **reverse proxy** (chuyển tiếp yêu cầu đến backend).
-   Hỗ trợ các tính năng như **cân bằng tải**, **caching**, **bảo mật** (SSL/TLS), và **nén dữ liệu**.
-   Đều được sử dụng rộng rãi trong các hệ thống web.

### 2. Điểm khác biệt

-   **Hiệu suất**:

    -   **Nginx**: Sử dụng mô hình **event-driven** (bất đồng bộ), phù hợp để xử lý số lượng lớn yêu cầu đồng thời với tài nguyên tối thiểu. Đặc biệt hiệu quả cho các tệp tĩnh (HTML, CSS, hình ảnh).
    -   **Apache**: Sử dụng mô hình **thread-based** hoặc **process-based**, tiêu tốn nhiều tài nguyên hơn khi xử lý hàng nghìn kết nối đồng thời.

-   **Cấu hình**:

    -   **Nginx**: Tệp cấu hình đơn giản, dễ hiểu, tập trung vào hiệu suất và định tuyến.
    -   **Apache**: Cấu hình phức tạp hơn, nhưng linh hoạt hơn với các mô-đun động (như mod_php cho ứng dụng PHP).

-   **Phù hợp với môi trường**:

    -   **Nginx**: Được ưa chuộng trong các hệ thống hiện đại như **Kubernetes**, **microservices**, hoặc **container** nhờ tốc độ và tính nhẹ.
    -   **Apache**: Phù hợp hơn cho các ứng dụng cần tích hợp chặt chẽ với các mô-đun như PHP, hoặc khi cần cấu hình phức tạp cho các ứng dụng cũ (legacy systems).

-   **Hỗ trợ giao thức**:
    -   **Nginx**: Hỗ trợ tốt **HTTP/3**, **gRPC**, và **WebSocket**, phù hợp với ứng dụng thời gian thực.
    -   **Apache**: Có hỗ trợ các giao thức này, nhưng không tối ưu bằng Nginx trong các môi trường container.
